{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Name : Sudarsun S\n",
        "RegNo: 20BCE1699\n",
        "Topic: Class Imbalance SMOTE & ADASYN\n",
        "Machine Learning Embedded Lab\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ECthYD7Qwkjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. GENERATE DATASET HAVING CLASS IMBALANCE (BINARY DATA)"
      ],
      "metadata": {
        "id": "5EB-KZyJx8qK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZylEyDY-v9G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cd5553-ae00-4c32-ab06-7926bd32451f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Feature1  Feature2  Target\n",
            "0 -0.400228 -0.926880     0.0\n",
            "1 -1.073630  1.199259     0.0\n",
            "2 -0.922953  0.306167     0.0\n",
            "3 -0.748422  2.103053     0.0\n",
            "4 -1.454758  2.645131     0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "np.random.seed(0)\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=2,\n",
        "    n_informative=2,\n",
        "    n_redundant=0,\n",
        "    n_classes=2,\n",
        "    weights=[0.95, 0.05],\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "data = pd.DataFrame(data=np.c_[X, y], columns=['Feature1', 'Feature2', 'Target'])\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. MAKE A DECISION TREE TO LEARN THE CLASIFICATION AND GENERATE THE ACCURACY, PRECISION AND RECALL"
      ],
      "metadata": {
        "id": "fVh1t9ESzLXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oFW4GCvymHb",
        "outputId": "eb8f85d2-51e5-4835-dcbf-27149cd4c6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Precision: 0.7777777777777778\n",
            "Recall: 0.6363636363636364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Show the problem in the above metrics\n",
        "\n",
        "\n",
        "\n",
        "*  Accuracy: Accuracy is not always a reliable metric when dealing with imbalanced datasets. In this case, if the model predicts the majority class (class 0) for most instances, it can achieve high accuracy because it's getting most of the samples right. However, it may perform poorly in terms of classifying the minority class (class 1).\n",
        "*   Precision: Precision is the fraction of relevant instances among the retrieved instances. In imbalanced datasets, precision might be low for the minority class because the model is less likely to correctly classify instances of that class. It's a problem if you want to minimize false positives for the minority class.\n",
        "\n",
        "\n",
        "*   Recall: Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. In imbalanced datasets, recall might be low for the minority class because the model might miss many of the actual instances of that class. It's a problem if you want to minimize false negatives for the minority class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NPegrVh00q-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Use SMOTE to increase the no of points in minority class"
      ],
      "metadata": {
        "id": "uz7-7k5d19Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkTqOqf-zdXB",
        "outputId": "c727ce0d-8081-4179-d292-a24a4d68d5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.10.1\n",
            "    Uninstalling imbalanced-learn-0.10.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.10.1\n",
            "Successfully installed imbalanced-learn-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=0)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "IjwL7hIY2Djt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Again train the decision tree and test it to get the precision, recall and accuracy"
      ],
      "metadata": {
        "id": "zr-6TTFd2kRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=0)\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeeNM4ny2jdi",
        "outputId": "3e4f290c-1436-460c-c430-2530cd1191d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9021164021164021\n",
            "Precision: 0.8854166666666666\n",
            "Recall: 0.918918918918919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Check if there is any improvement in the metrics\n",
        "\n",
        "Comparing the metrics before and after SMOTE, we can observe the following changes:\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy decreased slightly from 0.97 to 0.9021164021164021.\n",
        "*   Precision improved from 0.7777777777777778 to 0.8854166666666666.\n",
        "*   Recall significantly improved from 0.6363636363636364 to 0.918918918918919.\n",
        "\n",
        "In this case, after applying SMOTE, there is a noticeable improvement in precision and a substantial improvement in recall, which suggests that the model is better at correctly classifying the minority class (class 1) while maintaining a relatively high level of precision for that class. However, the accuracy decreased, which can be expected when dealing with a more balanced dataset."
      ],
      "metadata": {
        "id": "xLhec7WQ37lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Similarly do the same for ADASYN"
      ],
      "metadata": {
        "id": "t5EYL6qn4TDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "adasyn = ADASYN(sampling_strategy='auto', random_state=0)\n",
        "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X, y)\n",
        "\n",
        "X_train_adasyn, X_test_adasyn, y_train_adasyn, y_test_adasyn = train_test_split(X_resampled_adasyn, y_resampled_adasyn, test_size=0.2, random_state=0)\n",
        "clf_adasyn = DecisionTreeClassifier(random_state=0)\n",
        "clf_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
        "y_pred_adasyn = clf_adasyn.predict(X_test_adasyn)\n",
        "\n",
        "accuracy_after_adasyn = accuracy_score(y_test_adasyn, y_pred_adasyn)\n",
        "precision_after_adasyn = precision_score(y_test_adasyn, y_pred_adasyn)\n",
        "recall_after_adasyn = recall_score(y_test_adasyn, y_pred_adasyn)\n",
        "\n",
        "print(\"Metrics after ADASYN:\")\n",
        "print(\"Accuracy:\", accuracy_after_adasyn)\n",
        "print(\"Precision:\", precision_after_adasyn)\n",
        "print(\"Recall:\", recall_after_adasyn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8fuZZUP2vu4",
        "outputId": "5f682055-7641-4311-99b4-fd4851924dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics after ADASYN:\n",
            "Accuracy: 0.8601583113456465\n",
            "Precision: 0.8497409326424871\n",
            "Recall: 0.8723404255319149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Compare the results using SMOTE and ADASYN\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy: SMOTE resulted in higher accuracy (0.9021) compared to ADASYN (0.8602). SMOTE improved accuracy more in this case.\n",
        "*   Precision: SMOTE also achieved a higher precision (0.8854) than ADASYN (0.8497).\n",
        "\n",
        "\n",
        "*   Recall: Recall after SMOTE (0.9189) is slightly higher than recall after ADASYN (0.8723). SMOTE performed better in terms of recall as well.\n",
        "\n",
        "In this specific scenario, SMOTE seems to outperform ADASYN in terms of accuracy, precision, and recall. However, the choice between SMOTE and ADASYN may depend on the specific characteristics of your dataset and your objectives. Different datasets may yield different results, so it's essential to consider the specific context when choosing a resampling method."
      ],
      "metadata": {
        "id": "NgWB_sIy6LPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using The Wine Dataset"
      ],
      "metadata": {
        "id": "tqKni42g_4Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vyQgA7lBSrg",
        "outputId": "374cb7a2-5f5a-4455-b4be-236ff340d459"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.3-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "winequality = pd.read_csv('winequality.csv')\n",
        "\n",
        "# Step 2: Make a Decision Tree for classification and generate metrics\n",
        "X = winequality.drop(\"quality\", axis=1)\n",
        "y = winequality[\"quality\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Step 3: Show problems in the metrics\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Step 2:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "\n",
        "# Step 4: Use SMOTE to increase the number of points in the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 5: Train the decision tree on the resampled data\n",
        "dt_classifier.fit(X_resampled, y_resampled)\n",
        "y_pred_resampled = dt_classifier.predict(X_test)\n",
        "\n",
        "accuracy_resampled = accuracy_score(y_test, y_pred_resampled)\n",
        "precision_resampled = precision_score(y_test, y_pred_resampled, average='weighted')\n",
        "recall_resampled = recall_score(y_test, y_pred_resampled, average='weighted')\n",
        "\n",
        "print(\"Step 5 (SMOTE):\")\n",
        "print(\"Accuracy:\", accuracy_resampled)\n",
        "print(\"Precision:\", precision_resampled)\n",
        "print(\"Recall:\", recall_resampled)\n",
        "\n",
        "# Step 7: Perform the same steps with ADASYN\n",
        "sampling_strategy = {3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000}\n",
        "\n",
        "adasyn = ADASYN(sampling_strategy=sampling_strategy, random_state=42)\n",
        "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "dt_classifier.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
        "y_pred_resampled_adasyn = dt_classifier.predict(X_test)\n",
        "\n",
        "accuracy_resampled_adasyn = accuracy_score(y_test, y_pred_resampled_adasyn)\n",
        "precision_resampled_adasyn = precision_score(y_test, y_pred_resampled_adasyn, average='weighted')\n",
        "recall_resampled_adasyn = recall_score(y_test, y_pred_resampled_adasyn, average='weighted')\n",
        "\n",
        "print(\"Step 7 (ADASYN):\")\n",
        "print(\"Accuracy:\", accuracy_resampled_adasyn)\n",
        "print(\"Precision:\", precision_resampled_adasyn)\n",
        "print(\"Recall:\", recall_resampled_adasyn)\n",
        "\n",
        "# Step 8: Compare the results between SMOTE and ADASYN\n",
        "print(\"Step 8 (Comparison):\")\n",
        "print(\"SMOTE vs. ADASYN - Accuracy:\")\n",
        "print(\"SMOTE:\", accuracy_resampled)\n",
        "print(\"ADASYN:\", accuracy_resampled_adasyn)\n",
        "print(\"SMOTE vs. ADASYN - Precision:\")\n",
        "print(\"SMOTE:\", precision_resampled)\n",
        "print(\"ADASYN:\", precision_resampled_adasyn)\n",
        "print(\"SMOTE vs. ADASYN - Recall:\")\n",
        "print(\"SMOTE:\", recall_resampled)\n",
        "print(\"ADASYN:\", recall_resampled_adasyn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwcUcikw4rhL",
        "outputId": "a68fe376-bd28-4b1c-a300-d617ebc5aabb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2:\n",
            "Accuracy: 0.559375\n",
            "Precision: 0.550005791860414\n",
            "Recall: 0.559375\n",
            "Step 5 (SMOTE):\n",
            "Accuracy: 0.546875\n",
            "Precision: 0.6010336492551567\n",
            "Recall: 0.546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 3 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 4 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 5 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 6 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 7 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 8 will be larger than the number of samples in the majority class (class #5 -> 551)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7 (ADASYN):\n",
            "Accuracy: 0.575\n",
            "Precision: 0.6114680012950572\n",
            "Recall: 0.575\n",
            "Step 8 (Comparison):\n",
            "SMOTE vs. ADASYN - Accuracy:\n",
            "SMOTE: 0.546875\n",
            "ADASYN: 0.575\n",
            "SMOTE vs. ADASYN - Precision:\n",
            "SMOTE: 0.6010336492551567\n",
            "ADASYN: 0.6114680012950572\n",
            "SMOTE vs. ADASYN - Recall:\n",
            "SMOTE: 0.546875\n",
            "ADASYN: 0.575\n"
          ]
        }
      ]
    }
  ]
}